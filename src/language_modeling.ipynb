{
 "metadata": {
  "name": "",
  "signature": "sha256:aaeeb8c946803d694d10415f2a03b52cc68fe09bcdd89da18ce66f6b8ef3d7a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Numeric Python\n",
      "import numpy as np\n",
      "\n",
      "# Natural Language ToolKit\n",
      "import nltk\n",
      "\n",
      "# System Libraries\n",
      "import csv\n",
      "import itertools\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "from datetime import datetime\n",
      "\n",
      "\n",
      "from datasets import load_data\n",
      "from rnn_np import RNNnp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_x, train_y = load_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading CSV file.. ../data/reddit-comments-2015-08.csv\n",
        "Parsed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79170 sentences\n",
        "Found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65751  unique word tokens\n",
        "Using Vocabulary of size 8000\n",
        "The least frequent word in the vocabulary is \"devoted\" and appeared 10 times\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Random Seed for reproducibility\n",
      "np.random.seed(1234)\n",
      "_VOCABULARY_SIZE = int(os.environ.get('VOCABULARY_SIZE', '8000'))\n",
      "_HIDDEN_DIM = int(os.environ.get('HIDDEN_DIM', '100'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = RNNnp(word_dim=_VOCABULARY_SIZE, hidden_dim=_HIDDEN_DIM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out, hs = model.forward_propagation(train_x[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(46, 8000)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Expected Loss for random projections:',np.log(_VOCABULARY_SIZE)\n",
      "print 'Actual Loss:', calculate_loss(model, train_x[:1000], train_y[:1000])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Expected Loss for random projections: 8.98719682066\n",
        "Actual Loss: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9.01390535568\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = np.argmax(out, axis=1)\n",
      "print predictions.shape\n",
      "print predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(46,)\n",
        "[4626 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682\n",
        " 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682\n",
        " 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682 5682\n",
        "    0]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "(79170,)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(79170,)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [x for x in range(np.random.randint(10, 20))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out[a][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "array([ 0.0001252 ,  0.00012491,  0.00012455, ...,  0.00012495,\n",
        "        0.00012509,  0.00012497])"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datasets import read_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sen = read_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reading CSV file.. ../data/reddit-comments-2015-08.csv\n",
        "Parsed"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79170 sentences\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sen[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "u\"SENTENCE_START_TOKEN i joined a new league this year and they have different scoring rules than i'm used to. SENTENCE_END_TOKEN\""
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ws = [w for w in sen[0].split(\" \")]\n",
      "ws10 = [w for w in sen[10].split(\" \")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "(19,\n",
        " 20,\n",
        " 37,\n",
        " 45,\n",
        " u'SENTENCE_START_TOKEN no one is going to be honest enough to run the check, see they\\'re a felon, and then all of a sudden immediately turn dishonest and say \"nah, you know what, here\\'s your gun anyway.\" SENTENCE_END_TOKEN')"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ws10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "[u'SENTENCE_START_TOKEN',\n",
        " u'no',\n",
        " u'one',\n",
        " u'is',\n",
        " u'going',\n",
        " u'to',\n",
        " u'be',\n",
        " u'honest',\n",
        " u'enough',\n",
        " u'to',\n",
        " u'run',\n",
        " u'the',\n",
        " u'check,',\n",
        " u'see',\n",
        " u\"they're\",\n",
        " u'a',\n",
        " u'felon,',\n",
        " u'and',\n",
        " u'then',\n",
        " u'all',\n",
        " u'of',\n",
        " u'a',\n",
        " u'sudden',\n",
        " u'immediately',\n",
        " u'turn',\n",
        " u'dishonest',\n",
        " u'and',\n",
        " u'say',\n",
        " u'\"nah,',\n",
        " u'you',\n",
        " u'know',\n",
        " u'what,',\n",
        " u\"here's\",\n",
        " u'your',\n",
        " u'gun',\n",
        " u'anyway.\"',\n",
        " u'SENTENCE_END_TOKEN']"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}